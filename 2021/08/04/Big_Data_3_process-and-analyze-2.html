<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico">
  <link rel="mask-icon" href="/images/favicon.ico" color="#222">
  <link rel="alternate" href="/atom.xml" title="WuYJ's Blog" type="application/atom+xml">
  <meta name="google-site-verification" content="5Qe7cJKUxVbZsElTq6w1brLkQhcYBQXjnRmvHbU4JKo">
  <meta name="baidu-site-verification" content="code-oJllhY8gxe">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-bounce.min.css">
  <script src="/lib/pace/pace.min.js"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.5.0',
    exturl: false,
    sidebar: {"position":"right","display":"hide","offset":12,"onmobile":true},
    copycode: {"enable":true,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: true,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>
  <meta name="description" content="简介 Spark最初的设计目标是使数据分析更快——不仅运行速度快，也要能快速、容易地编写程序。为了使程序运行更快， Spark提供了内存计算，减少了迭代计算时的IO开销；而为了使编写程序更为容易， Spark使用简练、优雅的Scala语言编写，基于Scala提供了交互式的编程体验。">
<meta name="keywords" content="大数据,基础">
<meta property="og:type" content="article">
<meta property="og:title" content="[大数据技术原理|第三篇 大数据处理与分析(2)]">
<meta property="og:url" content="https:&#x2F;&#x2F;wuyunjie.top&#x2F;2021&#x2F;08&#x2F;04&#x2F;Big_Data_3_process-and-analyze-2.html">
<meta property="og:site_name" content="WuYJ&#39;s Blog">
<meta property="og:description" content="简介 Spark最初的设计目标是使数据分析更快——不仅运行速度快，也要能快速、容易地编写程序。为了使程序运行更快， Spark提供了内存计算，减少了迭代计算时的IO开销；而为了使编写程序更为容易， Spark使用简练、优雅的Scala语言编写，基于Scala提供了交互式的编程体验。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;wwwwwyj&#x2F;image_repository&#x2F;master&#x2F;img&#x2F;blog&#x2F;JavaLearning&#x2F;bigData&#x2F;chapter3&#x2F;BDAS.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;wwwwwyj&#x2F;image_repository&#x2F;master&#x2F;img&#x2F;blog&#x2F;JavaLearning&#x2F;bigData&#x2F;chapter3&#x2F;Spark.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;wwwwwyj&#x2F;image_repository&#x2F;master&#x2F;img&#x2F;blog&#x2F;JavaLearning&#x2F;bigData&#x2F;chapter3&#x2F;SparkWork.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;wwwwwyj&#x2F;image_repository&#x2F;master&#x2F;img&#x2F;blog&#x2F;JavaLearning&#x2F;bigData&#x2F;chapter3&#x2F;SparkDependency.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;wwwwwyj&#x2F;image_repository&#x2F;master&#x2F;img&#x2F;blog&#x2F;JavaLearning&#x2F;bigData&#x2F;chapter3&#x2F;SparkStage.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;wwwwwyj&#x2F;image_repository&#x2F;master&#x2F;img&#x2F;blog&#x2F;JavaLearning&#x2F;bigData&#x2F;chapter3&#x2F;SparkRunProcess.png">
<meta property="og:updated_time" content="2021-08-04T08:51:49.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;wwwwwyj&#x2F;image_repository&#x2F;master&#x2F;img&#x2F;blog&#x2F;JavaLearning&#x2F;bigData&#x2F;chapter3&#x2F;BDAS.png">

<link rel="canonical" href="https://wuyunjie.top/2021/08/04/Big_Data_3_process-and-analyze-2.html">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>[大数据技术原理|第三篇 大数据处理与分析(2)] | WuYJ's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">WuYJ's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">wuyunjie的小站</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
        <li class="menu-item menu-item-books">

    <a href="/books/" rel="section"><i class="fa fa-fw fa-book"></i>书单</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wuyunjie.top/2021/08/04/Big_Data_3_process-and-analyze-2.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/header.jpg">
      <meta itemprop="name" content="wuyunjie">
      <meta itemprop="description" content="这是一个为了有博客而存在的博客。 会在这里记录技术学习，读书感悟，生活日记等等。欢迎呀！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WuYJ's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          [大数据技术原理|第三篇 大数据处理与分析(2)]
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-08-04 16:51:49" itemprop="dateCreated datePublished" datetime="2021-08-04T16:51:49+08:00">2021-08-04</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>
            </span>

          
            <span id="/2021/08/04/Big_Data_3_process-and-analyze-2.html" class="post-meta-item leancloud_visitors" data-flag-title="[大数据技术原理|第三篇 大数据处理与分析(2)]" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/08/04/Big_Data_3_process-and-analyze-2.html#comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/08/04/Big_Data_3_process-and-analyze-2.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>6.3k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>6 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h3 id="简介">简介</h3>
<p><code>Spark</code>最初的设计目标是使数据分析更快——不仅运行速度快，也要能快速、容易地编写程序。为了使程序运行更快， <code>Spark</code>提供了内存计算，减少了迭代计算时的<code>IO开销</code>；而为了使编写程序更为容易， <code>Spark</code>使用简练、优雅的<code>Scala</code>语言编写，基于<code>Scala</code>提供了交互式的编程体验。</p>
<a id="more"></a>
<h3 id="spark概述">1. Spark概述</h3>
<h4 id="spark简介">1.1 Spark简介</h4>
<p><code>Spark</code>具有如下4个主要特点：</p>
<ol type="1">
<li><strong>运行速度快</strong>。<code>Spark</code>使用先进的<code>DAG（ Directed Acyclic Graph，有向无环图）</code>执行引擎，以支持循环数据流与内存计算，基于内存的执行速度可比 Hadoop MapReduce快上百倍。</li>
<li><strong>容易使用</strong>。<code>Spark</code>支持使用<code>Scala、Java、Python</code>和<code>R</code>语言进行编程，简洁的API设计有助于用户轻松构建并行程序，并且可以通过<code>Spark Shell</code>进行交互式编程。</li>
<li><strong>通用性</strong>。<code>Spark</code>提供了完整而强大的技术栈，包括<strong>SQL查询、流式计算、机器学习和图算法</strong>组件，这些组件可以无缝整合在同一个应用中，足以应对复杂的计算。</li>
<li><strong>运行模式多样</strong>。 <code>Spark</code>可运行于独立的集群模式中，或者运行于<code>Hadoop</code>中，也可运行于<code>Amazon EC2</code>等云环境中，并且可以访问<code>HDFS</code>、<code>Cassandra</code>、<code>HBase</code>、<code>Hive</code>等多种数据源。</li>
</ol>
<h4 id="scala简介">1.2 Scala简介</h4>
<p><code>Scala</code>是一门现代的多范式编程语言，平滑地集成了面向对象和函数式语言的特性，旨在以简练、优雅的方式来表达常用编程模式。<code>Scala</code>语言的名称来自于<code>“可扩展的语言（ A Scalable Language）"</code>，从写个小脚本到建立个大系统的编程任务均可胜任。<code>Scala</code>运行于<code>JVM</code>上，兼容现有的<code>Java</code>程序。总体而言，<code>Scala</code>具有以下突出的优点。</p>
<ul>
<li><code>Scala</code>具备强大的并发性，支持函数式编程，可以更好地支持分布式系统。</li>
<li><code>Scala</code>语法简洁，能提供优雅的API。</li>
<li><code>Scala</code>兼容<code>Java</code>，运行速度快，且能融合到 Hadoop生态圈中。</li>
</ul>
<h4 id="spark与hadoop的对比">1.3 <code>Spark</code>与<code>Hadoop</code>的对比</h4>
<p><code>Hadoop</code>最主要的缺陷是其MapReduce计算模型延迟过高，无法胜任实吋、快速计算的需求，因而只适用于离线批处理的应用场景。<code>Hadoop</code>主要存在以下缺点：</p>
<ul>
<li><strong>表达能力有限</strong>。计算都必须要转化成<code>Map</code>和<code>Reduce</code>两个操作，难以描述复杂的数据处理过程。</li>
<li><strong>磁盘IO开销大</strong>。每次执行时都需要从磁盘读取数据，并且在计算完成后需要将中间结果写入到磁盘中。</li>
<li><strong>延迟高</strong>。一次计算可能需要分解成一系列按顺序执行的<code>MapReduce</code>任务，任务之间的衔接由于涉及到<code>IO</code>开销，会产生较高延迟。在前一个任务执行完成之前，其他任务无法开始。</li>
</ul>
<p><code>Spark</code>在借鉴<code>Hadoop MapReduce</code>优点的同时，很好地解决了<code>MapReduce</code>所面临的问题。<code>Spark</code>主要具有如下优点：</p>
<ul>
<li><strong><u>编程模型比<code>MapReduce</code>更灵活</u></strong>。<code>Spark</code>的计算模式也属于<code>MapReduce</code>，但不局限于<code>Map</code>和<code>Reduce</code>操作，还提供了多种数据集操作类型。</li>
<li><code>Spark</code>提供了<strong>内存计算</strong>，中间结果直接放到内存中，带来了更高的迭代运算效率。</li>
<li><code>Spark</code>基于<code>DAG</code>的任务调度执行机制，要优于<code>MapReduce</code>的迭代执行机制。</li>
</ul>
<p><code>Spark</code>最大的特点就是<strong><u>将计算数据、中间结果都存储在内存中，大大减少了IO开销</u></strong>，因而<code>Spark</code>更适合于<strong><u>迭代运算比较多的数据挖掘与机器学习运算</u></strong>。</p>
<p><code>Spark</code>并不能完全替代<code>Hadoop</code>，主要用于替代<code>Hadoop</code>中的<code>MapReduce</code>计算模型，它可以借助于<code>YARN</code>实现资源调度管理，借助于<code>HDFS</code>实现分布式存储。<code>Spak</code>对硬件的要求稍高，对内存喝CPU有一定要求。</p>
<h3 id="spark生态系统">2. Spark生态系统</h3>
<p><code>Spark</code>的设计遵循<code>“一个软件栈满足不同应用场景”</code>的理念，逐渐形成了一套完整的生态系统，既能够提供内存计算框架，也可以支持<code>SQL</code>即席査询、实时流式计算、机器学习和图计算等。<code>Spark</code>可以部署在资源管理器<code>YARN</code>之上，提供一站式的大数据解决方案。</p>
<p><code>Spark</code>生态系统已经成为<strong>伯克利数据分析软件栈</strong><code>BDAS（Berkeley Data Analytics Stack）</code>。</p>
<figure>
<img src="https://raw.githubusercontent.com/wwwwwyj/image_repository/master/img/blog/JavaLearning/bigData/chapter3/BDAS.png" alt="伯克利数据分析软件栈BDAS" /><figcaption aria-hidden="true">伯克利数据分析软件栈BDAS</figcaption>
</figure>
<p><code>Spak</code>生态系统主要包含了<code>Spark Core</code>、<code>Spark SQL</code>、<code>Spark Streaming</code>、<code>MLlib</code>和<code>GraphX</code>等组件，各个组件的具体功能如下。</p>
<ol type="1">
<li><strong>Spark Core</strong>。Spark Core包含<code>Spark</code>的基本功能，如内存计算、任务调度、部署模式、故障恢复、存储管理等，主要面向批数据处理。<code>Spark</code>建立在统一的抽象<code>RDD</code>之上，使其可以<strong><u>以基本一致的方式应对不同的大数据处理场景</u></strong>。</li>
<li><strong>Spark SQL</strong>。Spark SQL允许开发人员直接处理<code>RDD</code>，同时也可查询Hive、HBase等外部数据源。Spark SQL的一个重要特点是其<strong><u>能够统一处理关系表和<code>RDD</code></u></strong>，开发人员可以轻松地使用SQL命令进行查询，进行更复杂的数据分析。</li>
<li><strong>Spark Streaming</strong>。Spark Streaming支持高吞吐量、可容错处理的实时流数据处理，其核心思路是<strong><u>将流数据分解成一系列短小的批处理作业</u></strong>，每个短小的批处理作业都可以使用Spark Core进行快速处理。Spark Streaming支持多种数据输入源，如 <code>Kafka</code>、<code>Flume</code>和<code>TCP</code>套接字等。</li>
<li><strong>MLlib（机器学习）</strong>。<code>MLlib</code>提供了常用机器学习算法的实现，包括聚类、分类、回归、协同过滤等。</li>
<li><code>GraphX（图计算）</code>。GraphX是<code>Spark</code>中用于图计算的API，可认为是<code>Pregel</code>在<code>Spark</code>上的重写及优化，<code>GraphX</code>性能良好，拥有丰富的功能和运算符，能在海量数据上自如地运行复杂的图算法。</li>
</ol>
<h3 id="spark-运行架构">3. Spark 运行架构</h3>
<h4 id="基本概念">3.1 基本概念</h4>
<ul>
<li><code>RDD</code>：即<code>弹性分布式数据集（ Resilient Distributed dataset）</code>，是分布式内存的一个抽象概念，提供了一种高度受限的<strong>共享内存模型</strong>；</li>
<li><code>DAG</code>：即<code>Directed Acyclic Graph（有向无环图）</code>，反映<code>RDD</code>之间的依赖关系</li>
<li><code>Executor</code>：运行在工作节点（Worker Node）上的一个进程，负责运行任务，并为应用程序存储数据。</li>
<li><code>Application</code>：用户编写的<code>Spark</code>应用程序。</li>
<li><code>Driver</code>：<code>Spark</code>中的<code>Driver</code>运行<code>Application</code>的<code>main</code>函数，并创建<code>SparkContext</code>准备<code>Spark</code>应用程序的运行环境。在<code>Spark</code>中由<code>SparkContext</code>负责与<code>ClusterManager</code>通信，进行资源申请、任务的分配和监控等，当<code>Executor</code>部分运行完毕后，<code>Driver</code>同时负责将<code>SparkContext</code>关闭。</li>
<li><code>Task</code>：运行在<code>Executor</code>上的工作单元。</li>
<li><code>Job</code>：一个作业包含多个<code>RDD</code>及作用于相应<code>RDD</code>上的各种操作。</li>
<li><code>Stage</code>：是作业的基本调度单位，一个作业会分为多组任务，每组任务被称为“阶段”，或者也被称为“任务集”。</li>
<li><code>CluterManager</code>：指集群上获取资源的外部服务。目前有三种类型
<ol type="1">
<li><code>Standalon</code> ：<code>Spark</code>原生的资源管理，由<code>Master</code>负责资源的分配</li>
<li><code>Apache Mesos</code>：与<code>Hadoop MR</code>兼容性良好的一种资源调度框架</li>
<li><code>Hadoop Yarn</code>：主要是指<code>Yarn</code>中的<code>ResourceManager</code></li>
</ol></li>
</ul>
<h4 id="架构设计">3.2 架构设计</h4>
<p>Spark运行架构，包括<code>集群资源管理器（Cluster Manager）</code>，运行作业任务的<code>工作节点（Worker Node）</code>、每个应用的<code>任务控制节点（Driver）</code>和每个工作节点上负责具体任务的<code>执行进程（Executor）</code>。集群资源管理器可以是<code>Spak</code>自带的资源管理器，也可以是<code>YARN</code>或<code>Mesos</code>等资源管理框架。</p>
<figure>
<img src="https://raw.githubusercontent.com/wwwwwyj/image_repository/master/img/blog/JavaLearning/bigData/chapter3/Spark.png" alt="Spark运行架构" /><figcaption aria-hidden="true">Spark运行架构</figcaption>
</figure>
<p><code>Spark</code>所采用的<code>Executor</code>有两个优点：</p>
<ul>
<li>利用多线程来执行具体的任务（Hadoop MapReduce采用的是进程模型），减少任务的启动开销；</li>
<li><code>Executor</code>中有一个<code>BlockManager</code>存储模块，会将内存和磁盘共同作为存储设备，当需要多轮迭代计算时，可以将中间结果存储到这个存储模块里，减少IO开销。</li>
</ul>
<p><code>Spark</code>中各个概念的关系为：</p>
<ul>
<li><code>Spark</code>中一个<code>应用（Application）</code>由一个<code>任务控制节点（Driver）</code>和若干个<code>作业（Job）</code>构成；</li>
<li>一个作业由多个<code>阶段（Stage）</code>构成；</li>
<li>一个阶段由多个<code>任务（Task）</code>组成。</li>
</ul>
<p>当执行一个应用时，任务控制节点会向集群管理器（Cluster Manager）申请资源，启动 Executor，并向Executor发送应用程序代码和文件，然后在Executor上执行任务，运行结束后执行结果会返回给任务控制节点，或者写到HDFS或者其他数据库中。</p>
<h4 id="spark运行基本流程">3.3 Spark运行基本流程</h4>
<p><code>Spark</code>运行基本流程如下：</p>
<ol type="1">
<li>当一个<code>Spak</code>应用被提交时，首先为这个应用构建<strong><u>基本运行环境</u></strong>，即由<code>任务控制节点（Driver）</code>创建一个<code>Spark Context</code>，由<code>Spark Context</code>负责和Cluster Manager的通信以及进行资源的申请、任务的分配和监控等。<code>Spark Context</code>会向资源管理器注册并申请运行Executor的资源。</li>
<li>资源管理器为Executor分配资源，并启动Executor进程，Executor运行情况将随着“心跳”发送到资源管理器上。</li>
<li><code>Spark Context</code>根据<code>RDD</code>的依赖关系构建<code>DAG</code>图，<code>DAG</code>图提交给<code>DAG调度器（DAG Scheduler）</code>进行解析，将DAG图分解成多个“阶段”，并且计算出各个阶段之间的依赖关系，然后把“任务集”提交给底层的<code>任务调度器（Task Scheduler）</code>进行处理；<code>Executor</code>向<code>Spark Context</code>申请任务，任务调度器将任务分发给<code>Executor</code>运行，同时<code>Spark Context</code>将应用程序代码发放给<code>Executor</code>；</li>
<li>任务在Executor运行，把执行结果反馈给任务调度器，然后反馈给DAG调度器，运行完毕后写入数据并释放所有资源。</li>
</ol>
<p><code>Spark</code>运行架构具有以下特点。</p>
<ul>
<li>每个应用都有自己专属的<code>Executor</code>进程，并且该进程在应用运行期间一直驻留。<code>Executor</code>进程以多线程的方式运行任务，减少了多进程任务频繁的启动开销。</li>
<li><code>Spark</code>运行过程与资源管理器无关，只要能够获取<code>Executor</code>进程并保持通信即可。</li>
<li><code>Executor</code>上有一个<code>BlockManager</code>存储模块，会将内存和磁盘共同作为存储设备，提高读写IO性能。</li>
<li>任务采用了<strong>数据本地性</strong>和<strong>推测执行</strong>等优化机制。</li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/wwwwwyj/image_repository/master/img/blog/JavaLearning/bigData/chapter3/SparkWork.png" alt="Spark运行基本流程" /><figcaption aria-hidden="true">Spark运行基本流程</figcaption>
</figure>
<h4 id="rdd的设计与运行原理">3.4 RDD的设计与运行原理</h4>
<h5 id="rdd的概念">3.4.1 RDD的概念</h5>
<p>一个<code>RDD</code>就是一个分布式对象集合，本质上是一个<strong><u>只读的分区记录集合</u></strong>。</p>
<ul>
<li><p>每个<code>RDD</code>可分成多个分区，每个分区就是一个<strong><u>数据集片段</u></strong>，并且一个<code>RDD</code>的不同分区可以被保存到集群中不同的节点上，从而<u><strong>可以在集群的不同节点上进行并行计算</strong></u>。</p></li>
<li><p><code>RDD</code>提供了一种高度受限的共享内存模型，即<code>RDD</code>是<strong><u>只读的记录分区的集合，不能直接修改</u></strong>。只能基于稳定的物理存储中的数据集创建<code>RDD</code>，或者通过在其他<code>RDD</code>上执行确定的转换操作（如<code>map</code>，<code>join</code>和<code>groupBy</code>）而创建得到新的<code>RDD</code>。</p></li>
</ul>
<p><code>RDD</code>提供了一组丰富的操作以支持常见的数据运算</p>
<ul>
<li><code>“行动”（Action）</code>。用于执行计算并指定输出的形式，行动操作（如<code>count</code>、<code>collect</code>等）<strong><u>接受<code>RDD</code>但是返回非<code>RDD</code></u></strong>（即输出一个值或结果）。</li>
<li><code>转换”（Transformation）</code>。指定<code>RDD</code>之间的相互依赖关系，转换操作（如<code>map</code>、<code>filter</code>、<code>groupBy</code>、<code>join</code>等）<strong><u>接受<code>RDD</code>并返回<code>RDD</code></u></strong>。</li>
</ul>
<p><code>RDD</code>执行过程：</p>
<ol type="1">
<li><code>RDD</code>读入外部数据源进行创建；</li>
<li><code>RDD</code>经过一系列的<code>转换（Transformation）</code>操作，每一次都会产生不同的<code>RDD</code>供下一个转换操作使用；</li>
<li>最后一个<code>RDD</code>经过<code>“动作”</code>操作进行处理，并输出到外部数据源。</li>
</ol>
<p><code>RDD</code>使用<strong>惰性调用</strong>：</p>
<ul>
<li>即在<code>RDD</code>的执行过程中，真正的计算发生在<code>RDD</code>的<code>“行动”</code>操作，对于<code>“行动”</code>之前的所有<code>“转换”</code>操作，<code>Spark</code>只记录<code>“转换”</code>操作应用的基础数据集以及<code>RDD</code>生成的轨迹，而不会触发真正的计算。</li>
<li><code>RDD</code>生成的轨迹称为一个<code>“血缘关系(Lineage)"</code>，即<code>DAG</code>拓扑排序的结果。</li>
<li>采用惰性调用，通过血缘关系连接起来的一系列<code>RDD</code>操作就可以实现<code>管道化（Pipeline）</code>，<strong><u>避免了多次转换操作之间数据同步的等待，而且不必担心有过多的中间数据</u></strong>。</li>
</ul>
<h5 id="rdd特性">3.4.2 RDD特性</h5>
<p><code>Spark</code>采用<code>RDD</code>以后能够实现高效计算的主要原因是：</p>
<ul>
<li><strong>高效的容错性</strong>。<code>RDD</code>是一种天生具有容错机制的特殊集合，只需通过<code>RDD</code>父子依赖（血缘）关系重新计算得到丢失的分区来实现容错，无需回滚整个系统，避免了数据复制的高开销。重算过程可以在不同节点之间并行进行，实现了高效的容错。</li>
<li><strong>中间结果持久化到内存</strong>。数据在内存中的多个<code>RDD</code>操作之间进行传递，避免了不必要的IO开销。</li>
<li>存放的数据可以是<code>Java对象</code>，避免了不必要的对象序列化和反序列化开销。</li>
</ul>
<h5 id="rdd之间的依赖关系">3.4.3 RDD之间的依赖关系</h5>
<p><code>RDD</code>中不同的操作会使得不同<code>RDD</code>中的分区产生不同的依赖。<code>RDD</code>中的依赖关系分为<code>窄依赖（Narrow Dependency）</code>与<code>宽依赖（Wide Dependency）</code>。</p>
<ul>
<li>窄依赖表现为一个或多个父<code>RDD</code>的分区对应于一个子<code>RDD</code>的分区。</li>
<li>宽依赖表现为存在一个父<code>RDD</code>的一个分区对应一个子<code>RDD</code>的多个分区。</li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/wwwwwyj/image_repository/master/img/blog/JavaLearning/bigData/chapter3/SparkDependency.png" alt="窄依赖与宽依赖" /><figcaption aria-hidden="true">窄依赖与宽依赖</figcaption>
</figure>
<p>如果<code>父RDD</code>的一个分区只被一个<code>子RDD</code>的一个分区所使用就是窄依赖，否则就是宽依赖。窄依赖典型的操作包括<code>map</code>、 <code>filter</code>、<code>union</code>等，宽依赖典型的操作包括 <code>groupByKey</code>、<code>sortByKey</code>等。</p>
<ul>
<li>对于窄依赖的RDD，可以以流水线的方式计算所有父分区，不会造成网络之间的数据混合。</li>
<li>对于宽依赖的RDD，则通常伴随着<code>Shuffle</code>操作，即<strong><u>首先需要计算好所有父分区数据，然后在节点之间进行 <code>Shuffle</code></u></strong>。</li>
</ul>
<p>相对而言，在两种依赖关系中，窄依赖的失败恢复更为高效，它只需要根据父RDD分区重新计算丢失的分区即可<strong>（不需要重新计算所有分区）</strong>，而且可以并行地在不同节点上进行重新计算。而对于宽依赖而言，单个节点失效通常意味着重新计算过程会涉及多个父RDD分区，开销较大。</p>
<p>在进行故障恢复时，<code>Spark</code>会对数据检查点开销和重新计算<code>RDD</code>分区的开销进行比较，从而自动选择最优的恢复策略。</p>
<h5 id="阶段的划分">3.4.4 阶段的划分</h5>
<p><code>Spark</code>通过分析各个RDD的依赖关系生成了<code>DAG</code>，再<strong><u>通过分析各个RDD中的分区之间的依赖关系来决定如何划分阶段</u></strong>，具体划分方法是：</p>
<ul>
<li>在<code>DAG</code>中进行反向解析，<strong><u>遇到宽依赖就断开，遇到窄依赖就把当前的<code>RDD</code>加入到当前的阶段中</u></strong>；</li>
<li>将窄依赖尽量划分在同一个阶段中可以实现流水线计算。</li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/wwwwwyj/image_repository/master/img/blog/JavaLearning/bigData/chapter3/SparkStage.png" alt="阶段的划分" /><figcaption aria-hidden="true">阶段的划分</figcaption>
</figure>
<p>这样划分的主要原因是：由于<code>shuffle</code>依赖必须等<code>RDD</code>的<code>父RDD</code>分区数据<strong><u>全部可读之后</u></strong>才能开始计算，因此<code>Spark</code>的设计是<strong><u>让父RDD将结果写在本地，完全写完之后，通知后面的RDD</u></strong>。后面的RDD则首先去读之前RDD的本地数据作为输入，然后进行运算。</p>
<ul>
<li>写入本地的原因是，后面的RDD多个分区都要去读这个信息，如果放到内存，假如出现数据丢失，后面所有的步骤全部不能进行，违背需要父RDD分区数据全部ready的原则。</li>
</ul>
<p>把一个DAG图划分成多个阶段以后，每个阶段都代表了一组<strong><u>关联的、相互之间没有<code>Shuffle</code>依赖关系的任务</u></strong>组成的任务集合。每个任务集合会被提交给任务调度器进行处理，由任务调度器将任务分发给Executor运行。</p>
<h5 id="rdd运行过程">3.4.5 RDD运行过程</h5>
<ul>
<li>创建RDD对象；</li>
<li><code>Spark Context</code>负责计算RDD之间的依赖关系，构建<code>DAG</code>；</li>
<li><code>DAGScheduler</code>负责把<code>DAG</code>图分解成多个阶段，每个阶段中包含了多个任务；</li>
<li>每个任务会被任务调度器分发给各个工作节点（ Worker Node）上的 Executor去执行。</li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/wwwwwyj/image_repository/master/img/blog/JavaLearning/bigData/chapter3/SparkRunProcess.png" alt="RDD运行过程" /><figcaption aria-hidden="true">RDD运行过程</figcaption>
</figure>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag"># 大数据</a>
              <a href="/tags/%E5%9F%BA%E7%A1%80/" rel="tag"># 基础</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
                <a href="/2021/08/04/Big_Data_3_process-and-analyze-1.html" rel="next" title="[大数据技术原理|第三篇 大数据处理与分析(1)]">
                  <i class="fa fa-chevron-left"></i> [大数据技术原理|第三篇 大数据处理与分析(1)]
                </a>
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
                <a href="/2021/08/05/JavaLearning_Regular-Expression.html" rel="prev" title="[Java|正则表达式]">
                  [Java|正则表达式] <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="comments"></div>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#简介"><span class="nav-number">1.</span> <span class="nav-text">简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#spark概述"><span class="nav-number">2.</span> <span class="nav-text">1. Spark概述</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#spark简介"><span class="nav-number">2.1.</span> <span class="nav-text">1.1 Spark简介</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#scala简介"><span class="nav-number">2.2.</span> <span class="nav-text">1.2 Scala简介</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#spark与hadoop的对比"><span class="nav-number">2.3.</span> <span class="nav-text">1.3 Spark与Hadoop的对比</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#spark生态系统"><span class="nav-number">3.</span> <span class="nav-text">2. Spark生态系统</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#spark-运行架构"><span class="nav-number">4.</span> <span class="nav-text">3. Spark 运行架构</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#基本概念"><span class="nav-number">4.1.</span> <span class="nav-text">3.1 基本概念</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#架构设计"><span class="nav-number">4.2.</span> <span class="nav-text">3.2 架构设计</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#spark运行基本流程"><span class="nav-number">4.3.</span> <span class="nav-text">3.3 Spark运行基本流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#rdd的设计与运行原理"><span class="nav-number">4.4.</span> <span class="nav-text">3.4 RDD的设计与运行原理</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#rdd的概念"><span class="nav-number">4.4.1.</span> <span class="nav-text">3.4.1 RDD的概念</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#rdd特性"><span class="nav-number">4.4.2.</span> <span class="nav-text">3.4.2 RDD特性</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#rdd之间的依赖关系"><span class="nav-number">4.4.3.</span> <span class="nav-text">3.4.3 RDD之间的依赖关系</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#阶段的划分"><span class="nav-number">4.4.4.</span> <span class="nav-text">3.4.4 阶段的划分</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#rdd运行过程"><span class="nav-number">4.4.5.</span> <span class="nav-text">3.4.5 RDD运行过程</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="wuyunjie"
      src="/images/header.jpg">
  <p class="site-author-name" itemprop="name">wuyunjie</p>
  <div class="site-description" itemprop="description">这是一个为了有博客而存在的博客。 会在这里记录技术学习，读书感悟，生活日记等等。欢迎呀！</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">135</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">20</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">42</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/wwwwwyj" title="GitHub → https://github.com/wwwwwyj" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="http://wuyunjie.top/loving/happy-birthday" title="Loving → http://wuyunjie.top/loving/happy-birthday"><i class="fa fa-fw fa-heartbeat"></i>Loving</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 2017 – 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">wuyunjie</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">570k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">8:38</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.0.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://mist.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.5.0
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>






  <script>
  function leancloudSelector(url) {
    return document.getElementById(url).querySelector('.leancloud-visitors-count');
  }
  if (CONFIG.page.isPost) {
    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = visitors.getAttribute('id').trim();
      var title = visitors.getAttribute('data-flag-title').trim();

      Counter('get', `/classes/Counter?where=${JSON.stringify({ url })}`)
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .then(response => response.json())
              .then(() => {
                leancloudSelector(url).innerText = counter.time + 1;
              })
              .catch(error => {
                console.log('Failed to save visitor count', error);
              })
          } else {
              Counter('post', '/classes/Counter', { title: title, url: url, time: 1 })
                .then(response => response.json())
                .then(() => {
                  leancloudSelector(url).innerText = 1;
                })
                .catch(error => {
                  console.log('Failed to create', error);
                });
          }
        })
        .catch(error => {
          console.log('LeanCloud Counter Error', error);
        });
    }
  } else {
    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return element.getAttribute('id').trim();
      });

      Counter('get', `/classes/Counter?where=${JSON.stringify({ url: { '$in': entries } })}`)
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length === 0) {
            document.querySelectorAll('.leancloud_visitors .leancloud-visitors-count').forEach(element => {
              element.innerText = 0;
            });
            return;
          }
          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.url;
            var time = item.time;
            leancloudSelector(url).innerText = time;
          }
          for (var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = leancloudSelector(url);
            if (element.innerText == '') {
              element.innerText = 0;
            }
          }
        })
        .catch(error => {
          console.log('LeanCloud Counter Error', error);
        });
    }
  }

  fetch('https://app-router.leancloud.cn/2/route?appId=xilgdic7Oc4jk1clqctOmHlW-gzGzoHsz')
    .then(response => response.json())
    .then(({ api_server }) => {
      var Counter = (method, url, data) => {
        return fetch(`https://${api_server}/1.1${url}`, {
          method: method,
          headers: {
            'X-LC-Id': 'xilgdic7Oc4jk1clqctOmHlW-gzGzoHsz',
            'X-LC-Key': '0mJaTLwPvm9HULVEKS5TMolA',
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        const localhost = /http:\/\/(localhost|127.0.0.1|0.0.0.0)/;
        if (localhost.test(document.URL)) return;
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    });
  </script>






        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/muse.js"></script>
<script src="/js/next-boot.js"></script>



  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>




  <script src="/js/local-search.js"></script>













  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  


<script>
NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(item => {
    return GUEST.includes(item);
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: true,
    appId: 'fuyVSSepSwnhxBAljzT0Wom8-MdYXbMMI',
    appKey: 'MeBSdvWlNAgNnXhX1HQ1QnA5',
    placeholder: "欢迎评论交流呀！\n输入邮箱可以收到回复通知哦!(昵称输入QQ可以自动识别邮箱和头像)",
    avatar: 'retro',
    meta: guest,
    pageSize: '10' || 10,
    visitor: false,
    lang: '' || 'zh-cn',
    path: location.pathname,
    enableQQ: true,
    recordIP: false,
    serverURLs: ''
  });
}, window.Valine);
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
